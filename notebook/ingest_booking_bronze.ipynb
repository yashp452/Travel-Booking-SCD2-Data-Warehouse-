{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f29015c-9be3-4f2e-a5cf-3b463be092c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e867f2df-bebd-4d01-8902-5092610fed5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime as _dt\n",
    "try:\n",
    "    arrival_date = dbutils.widgets.get(\"arrival_date\")\n",
    "except Exception:\n",
    "    arrival_date = _dt.date.today().strftime(\"%Y-%m-%d\")\n",
    "try:\n",
    "    catalog = dbutils.widgets.get(\"catalog\")\n",
    "except Exception:\n",
    "    catalog = \"travel_bookings\"\n",
    "try:\n",
    "    schema = dbutils.widgets.get(\"schema\")\n",
    "except Exception:\n",
    "    schema = \"default\"\n",
    "try:\n",
    "    base_volume = dbutils.widgets.get(\"base_volume\")\n",
    "except Exception:\n",
    "    base_volume = f\"/Volumes/{catalog}/{schema}/data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a0bc633-1ca2-40b5-8e11-d8a1159ee572",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "booking_path = f\"{base_volume}/booking_data/bookings_{arrival_date}.csv\"\n",
    "\n",
    "df = (spark.read.format(\"csv\")\n",
    "      .option(\"header\",\"true\").option(\"inferSchema\",\"true\")\n",
    "      .option(\"quote\",\"\\\"\").option(\"multiLine\",\"true\")\n",
    "      .load(booking_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f97b8b45-a77c-4cdd-b966-cea3acfebed5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"ingestion_time\", current_timestamp()) \\\n",
    "       .withColumn(\"business_date\", F.to_date(F.lit(arrival_date)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ef0f092-dea6-4d02-97f6-fac397fb87d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.bronze\")\n",
    "\n",
    "df.write.format(\"delta\").mode(\"append\").saveAsTable(f\"{catalog}.bronze.booking_inc\")\n",
    "\n",
    "print(f\"Ingested rows: {df.count()}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingest_booking_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
