{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7135a96b-fb69-451f-835a-b726ad7b6a5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import datetime as _dt\n",
    "try:\n",
    "    arrival_date = dbutils.widgets.get(\"arrival_date\")\n",
    "except Exception:\n",
    "    arrival_date = _dt.date.today().strftime(\"%Y-%m-%d\")\n",
    "try:\n",
    "    catalog = dbutils.widgets.get(\"catalog\")\n",
    "except Exception:\n",
    "    catalog = \"travel_bookings\"\n",
    "try:\n",
    "    schema = dbutils.widgets.get(\"schema\")\n",
    "except Exception:\n",
    "    schema = \"default\"\n",
    "\n",
    "# =============================================================================\n",
    "# SOURCE DATA PREPARATION\n",
    "# =============================================================================\n",
    "# Load booking data from bronze layer for the specified business date\n",
    "# Filters to current day's data for incremental processing\n",
    "\n",
    "book = spark.table(f\"{catalog}.bronze.booking_inc\").where(F.col(\"business_date\") == F.to_date(F.lit(arrival_date)))\n",
    "\n",
    "# =============================================================================\n",
    "# DIMENSION INTEGRATION\n",
    "# =============================================================================\n",
    "# Load current customer dimension records with surrogate keys\n",
    "# Joins booking data with customer dimension to get surrogate keys\n",
    "# Uses LEFT JOIN to preserve all bookings even if customer not in dimension\n",
    "\n",
    "current_dim = spark.sql(f\"SELECT customer_sk, customer_id FROM {catalog}.{schema}.customer_dim WHERE is_current = true\")\n",
    "\n",
    "book_enriched = (book.alias(\"b\")\n",
    "  .join(current_dim.alias(\"d\"), F.col(\"b.customer_id\") == F.col(\"d.customer_id\"), \"left\")\n",
    "  .withColumn(\"customer_sk\", F.col(\"d.customer_sk\")))\n",
    "\n",
    "# =============================================================================\n",
    "# FACT TABLE COLUMN SELECTION\n",
    "# =============================================================================\n",
    "# Select relevant columns for fact table aggregation\n",
    "# Includes booking_type, customer keys, business_date, and financial metrics\n",
    "\n",
    "book_enriched_sel = book_enriched.select(\n",
    "    F.col(\"booking_type\"),\n",
    "    F.col(\"b.customer_id\").alias(\"customer_id\"),\n",
    "    F.col(\"customer_sk\"),\n",
    "    F.col(\"business_date\"),\n",
    "    F.col(\"amount\"),\n",
    "    F.col(\"discount\"),\n",
    "    F.col(\"quantity\")\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# FACT TABLE AGGREGATION\n",
    "# =============================================================================\n",
    "# Aggregate booking data to daily grain by booking_type, customer, and date\n",
    "# Calculates total amount (after discount) and total quantity\n",
    "# Daily grain provides idempotent processing and business-friendly aggregation\n",
    "\n",
    "agg = (book_enriched_sel.groupBy(\"booking_type\",\"customer_sk\",\"customer_id\",\"business_date\")\n",
    "        .agg(F.sum(F.col(\"amount\") - F.col(\"discount\")).alias(\"total_amount_sum\"),\n",
    "             F.sum(\"quantity\").alias(\"total_quantity_sum\")))\n",
    "\n",
    "fact_full_name = f\"{catalog}.{schema}.booking_fact\"\n",
    "\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\")\n",
    "\n",
    "if not spark.catalog.tableExists(fact_full_name):\n",
    "  a = agg.limit(0)\n",
    "  a.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\",\"true\").saveAsTable(fact_full_name)\n",
    "\n",
    "\n",
    "agg.createOrReplaceTempView(\"src\")\n",
    "spark.sql(f\"\"\"\n",
    "  MERGE INTO {fact_full_name} t\n",
    "  USING src s\n",
    "  ON  t.booking_type = s.booking_type\n",
    "  AND t.customer_sk <=> s.customer_sk\n",
    "  AND t.business_date = s.business_date\n",
    "  WHEN MATCHED THEN UPDATE SET\n",
    "    t.total_amount_sum = s.total_amount_sum,\n",
    "    t.total_quantity_sum = s.total_quantity_sum,\n",
    "    t.customer_id = s.customer_id\n",
    "  WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "print(\"Fact build complete (daily grain, surrogate key)\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "booking_fact",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
